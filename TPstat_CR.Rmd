---
pathOpt <- c(1,8,9,4,21,13,7,10,3,17,16,20,6,19,15,18,11,5,22,14,12,2)---

```{r setup, include=FALSE, cache = FALSE}
knitr::opts_chunk$set(echo = TRUE)

## il est possible qu'avant d'installer le package TSPpackage vous deviez installer ou ré-installer Rcpp
#install.packages('Rcpp')

# install.packages('./TSPpackage_1.0.tar.gz',repos=NULL,type='bin') ## pour linux
# install.packages('./TSPpackage_1.0.zip',repos=NULL,type='bin')    ## pour windows
## je ne peux pas fournir de package pour mac...

## Appels aux packages, après les avoir installés !
library(sp)
library(maps)
library(microbenchmark)
library(TSP)
library(TSPpackage)

## Fixer la graine
set.seed(420)
```

# 0. Visualisation de chemins

Lecture du fichier des villes de la France:

```{r, echo=TRUE}
villes <- read.csv('Data/DonneesGPSvilles.csv',header=TRUE,dec='.',sep=';',quote="\"")
```

Représentation des chemins par plus proches voisins et du chemin optimal :
```{r, echo=TRUE}
coord <- cbind(villes$longitude,villes$latitude)
dist <- distanceGPS(coord)
voisins <- TSPnearest(dist)
pathOpt <- c(1,8,9,4,21,13,7,10,3,17,16,20,6,19,15,18,11,5,22,14,12,2)
par(mfrow=c(1,2),mar=c(1,1,2,1))
plotTrace(coord[voisins$chemin,], title='Plus proches voisins')
plotTrace(coord[pathOpt,], title='Chemin optimal')
```


Les longueurs des trajets (à vol d'oiseau) valent respectivement, pour la méthode des plus proches voisins :
```{r, echo=FALSE}
voisins$longueur
```
pour la méthode branch and bound :
```{r, echo=FALSE}
TSPsolve(dist,'branch')
```
et pour la méthode optimale :
```{r, echo=FALSE}
calculeLongueur(dist,pathOpt)
```

Nous voyons clairement que la méthode de plus proches voisins trouve un chemin moins optimal que la méthode branch and bound. De plus le chemin trouvé par cette méthode est bien plus long que le chemin optimale.
Ceci illustre bien l'intérêt d'un algorithme de voyageur de commerce. Nous allons dans la suite étudier les performances de cet algorithme.


# 1. Comparaison d'algorithmes

Nous allons comparer
Nombre de sommets fixes et graphes "identiques".

```{r, echo=TRUE}
nb_essais <- 5
d_hamil <- matrix(0,nrow=nb_essais,ncol=5)
for (i in 1:nb_essais) {
  n <- 10
  sommets <- data.frame(x = runif(n), y = runif(n))
  couts <- distance(sommets)
  d_hamil[i, 1] <- TSPsolve(couts, 'repetitive_nn')
  d_hamil[i, 2] <- TSPsolve(couts, 'nearest_insertion')
  d_hamil[i, 3] <- TSPsolve(couts, 'two_opt')
  d_hamil[i, 4] <- TSPsolve(couts, 'nearest')
  d_hamil[i, 5] <- TSPsolve(couts, 'branch')
}
colnames(d_hamil) <- c('Rep nn','Nearest i','Two opt','Nearest','Branch')
par(mfrow=c(1,1))
boxplot(d_hamil)

```

## 1.1. Longueur des chemins

Comparaison des longueurs de différentes méthodes : 

### Boxplots

```{r, echo=TRUE}
nb_essais <- 50
d_hamil <- matrix(0,nrow=nb_essais,ncol=5)
for (i in 1:nb_essais) {
  n <- 10
  sommets <- data.frame(x = runif(n), y = runif(n))
  couts <- distance(sommets)
  d_hamil[i, 1] <- TSPsolve(couts, 'repetitive_nn')
  d_hamil[i, 2] <- TSPsolve(couts, 'nearest_insertion')
  d_hamil[i, 3] <- TSPsolve(couts, 'two_opt')
  d_hamil[i, 4] <- TSPsolve(couts, 'nearest')
  d_hamil[i, 5] <- TSPsolve(couts, 'branch')
}
colnames(d_hamil) <- c('Rep nn','Nearest i','Two opt','Nearest','Branch')
par(mfrow=c(1,1))
boxplot(d_hamil)

```

### Test entre 'nearest' et 'branch'

```{r, echo=TRUE}
htest = t.test(d_hamil[,4], d_hamil[,5], paired=TRUE)
# p_valeur <= 5 e-10 => On peut rejetter H0 avec certitude => H1 est admissible => mmnn -mmb > 0, branch and bound trouve une meilleure chemin optimale que nearest neighbour

```



   * tests 2 à 2 
```{r, echo=TRUE}
methods <- matrix(0,nrow=nb_essais,ncol=5)
for (i in 1:nb_essais) {
  methods[i, 1] <- 'repetitive_nn'
  methods[i, 2] <- 'nearest_insertion'
  methods[i, 3] <- 'two_opt'
  methods[i, 4] <- 'nearest'
  methods[i, 5] <- 'branch'
}
m_results<-as.vector(d_hamil)
m_methods<-as.vector(methods)
pairwise.t.test(m_results, m_methods,adjust.method='bonferroni', paired=T)

#faire les deux tests sans paired=TRUE et avec
#sans paired=TRUE : juste et on peut faire une analyse comparative 2 à 2, on obtient des résultats qui montrent qu'un certains nombre d'algorithmes sont équivalents, quelques avantages significatifs de branch et bound tout de même, sauf pour nn
#avec paired=TRUE : ce paramètre est admisible car nous avons construits nos résultats de chemins hamiltoniens en utilisant les mêmes valeurs pour les 5 algorithmes à chaque fois. Il est ici pertiennt d'utiliser ce paramètre et nous obtenons de meilleurs résultats !
#ici nous pouvons dire que branch and bound est meilleur que tous les autres algorithmes pour le calcul du chemin hamiltonien optimal. Finalement, nous obtenons que deux algo seulement sont équivalents : two_opt/nearest et two_opt```
```
## 1.2. Temps de calcul

Comparaison des temps à l'aide du package microbenchmark.

Exemple d'application de microbenchmark :
```{r, echo=TRUE}

# temps <- matrix(0,nrow=17,ncol=5)
  
microbenchmark(TSPsolve(couts, 'repetitive_nn'),TSPsolve(couts, 'nearest'),TSPsolve(couts, 'nearest_insertion'),TSPsolve(couts, 'branch'),TSPsolve(couts, 'two_opt'), times=20, unit="ms", setup={sommets<- data.frame(x = runif(n), y = runif(n))
couts <- distance(sommets)})

#nous obtenons les résultats suivants à l'exécution :
# repretitive_nn : d
# nearest : a
# nearest_insertion : b
# branch : c
# two_opt : ab
# Si branch and bound est donc assez clairement le meilleur algorithme de calcul de chemin hamiltionien optimal, il est donc loin d'être le plus rapide. Le plus lent restant quand même repetitive_nn.
# Il est intéressant de remarquer ici que nearest et nearest_insertion ne sont pas aussi rapides l'un que l'autre, pourtant, la vitesse d'exécution de two_opt est comparable à celle de nearest et à celle de nearest_insertion ! Toutefois, d'une exécution à l'autre, le temps de calcul peut changer et il sera donc tout à fait possible d'obtenir soit seulement a, soit seulement b pour two_opt
```

# 2. Etude e la complexité de l'algorithme Branch and Bound

## 2.1. Comportement par rapport au nombre de sommets : premier modèle

Récupération du temps sur 10 graphes pour différentes valeurs de $n$.
```{r, echo=TRUE}
seqn <- seq(4,20,1)
times <- 10
temps <- matrix(0,nrow=length(seqn),ncol=times)

for (i in 1:length(seqn)) {
  temps[i,]<- t(microbenchmark(TSPsolve(couts, method = 'branch'),
  times = times,
  setup = { n <- seqn[i]
            couts <- distance(cbind(x = runif(n), y = runif(n)))}
  )$time)
}
par(mfrow=c(2,2)) # 2 graphiques sur 1 ligne
# par(mfrow=c(1,2)) # 2 graphiques sur 1 ligne
matplot(seqn, temps, xlab='n', ylab='temps')
matplot(seqn, log(temps)^2, xlab='n', ylab=expression(log(temps)^2))
#le temps de calcul évolue de manière exponentielle en fonction de n, nous allons donc plutôt utiliser le gogarithme du temps de calcul pour se ramener à une répartition linéaire
```

Ajustement du modèle linéaire de $\log(temps)^2$ en fonction de $n$.
Adding random text here

```{r, echo=TRUE}
vect_temps <- log(as.vector(temps))^2
vect_dim <- rep(seqn,times=10)
temps.lm <- lm(vect_temps ~ vect_dim)
summary(temps.lm)
```
Etude graphique des analyse de résidus.
```{r, echo=TRUE}
par(mfrow=c(2,2)) # 4 graphiques, sur 2 lignes et 2 colonnes
plot(temps.lm)

shapiro.test(residuals(temps.lm))
#on fait le test de shapiro car les extremités de notre Normal Q-Q modèle s'éloigent de la bisectrice, on obtient ici pour une exécution p-value=0.01463 par exemple. C'est une valeur très petite, on rejette la loi normale.
```

Analyse de la validité du modèle : 

  * pertinence des coefficients et du modèle, 
  
  * étude des hypothèses sur les résidus.

## 2.2. Comportement par rapport au nombre de sommets : étude du comportement moyen

Récupération du temps moyen.

Ajustement du modèle linéaire de $\log(temps.moy)^2$ en fonction de $n$.
```{r, echo=TRUE}
seqn <- seq(4,20,1)
times <- 10
temps <- matrix(0,nrow=length(seqn),ncol=times)


for (i in 1:length(seqn)) {
  temps[i,]<- t(microbenchmark(TSPsolve(couts, method = 'branch'),
  times = times,
  setup = { n <- seqn[i]
            couts <- distance(cbind(x = runif(n), y = runif(n)))}
  )$time)
}
temps_moy <- rowMeans(temps)
par(mfrow=c(2,2)) # 2 graphiques sur 1 ligne
# par(mfrow=c(1,2)) # 2 graphiques sur 1 ligne
matplot(seqn, temps_moy, xlab='n', ylab='temps.moy')
matplot(seqn, log(temps_moy)^2, xlab='n', ylab=expression(log(temps_moy)^2))
#le temps de calcul évolue de manière exponentielle en fonction de n, nous allons donc plutôt utiliser le gogarithme du temps de calcul pour se ramener à une répartition linéaire
```
Ajustement du modèle linéaire de $\log(temps)^2$ en fonction de $n$.
```{r, echo=TRUE}
vect_temps_moy <- log(as.vector(temps_moy))^2
vect_dim_moy <- rep(seqn,1)
temps_moy.lm <- lm(vect_temps_moy ~ vect_dim_moy)
summary(temps_moy.lm)
```
Etude graphique des analyse de résidus.
```{r, echo=TRUE}
par(mfrow=c(2,2)) # 4 graphiques, sur 2 lignes et 2 colonnes
plot(temps_moy.lm)

shapiro.test(residuals(temps_moy.lm))
#
```


Analyse de la validité du modèle : 

  * pertinence des coefficients et du modèle, 
  
  * étude des hypothèses sur les résidus.
  

## 2.3. Comportement par rapport à la structure du graphe

Lecture du fichier 'DonneesTSP.csv'.

Ajustement du modèle linéaire de $\log(temps.moy)^2$ en fonction de toutes les variables présentes. Modèle sans constante.

Mise en \oe uvre d'une sélection de variables pour ne garder que les variables pertinentes.

Analyse de la validité du modèle : 

  * pertinence des coefficients et du modèle, 
  
  * étude des hypothèses sur les résidus.
  
```{r, echo=TRUE}
data.graph <- data.frame(read.csv('Data/DonneesTSP.csv',header=TRUE,dec='.',sep=',',quote="\""))
# dataset_columns <- c("dim", "mean.long","mean.dist", "sd.dist", "mean.deg", "sd.deg", "diameter")
data.graph$dim <- sqrt(data.graph$dim)
temps_tsp.lm <- lm(log(tps) ~ ., data=data.graph)

summary(temps_tsp.lm)
par(mfrow=c(2,2)) # 4 graphiques, sur 2 lignes et 2 colonnes
plot(temps_tsp.lm)

shapiro.test(residuals(temps_tsp.lm))
```
Elimlination des variables non significatives
```{r, echo=TRUE}
summary(step(temps_tsp.lm))
par(mfrow=c(2,2)) # 4 graphiques, sur 2 lignes et 2 colonnes
plot(step(temps_tsp.lm))

shapiro.test(residuals(step(temps_tsp.lm)))
```
  

